{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOPP 2020W Exercise 3\n",
    "## Group 10\n",
    "\n",
    "**Question:**\n",
    "\n",
    "How has the use of nuclear energy evolved over time? How well does the use of nuclear energy correlate with changes in carbon emissions? Are there characteristics of a country that correlate with increases or decreases in the use of nuclear energy?\n",
    "\n",
    "**Members:**\n",
    "\n",
    "* Josef Glas 08606876\n",
    "* Felix Korbelius 01526132\n",
    "* Frank Ebel 01429282\n",
    "* Johannes Schabbauer 11776224\n",
    "\n",
    "**Work method:**\n",
    "\n",
    "Each person wrote python scripts for their respective tasks. These scripts were merged in this notebook by Frank and modified if necessary. <br> <span style=\"color:red\">todo_frank Link to GitHub repository?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading necessary modules\n",
    "\n",
    "Since we have widgets, this option must be run first:\\\n",
    "`jupyter nbextension enable --py widgetsnbextension --sys-prefix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file manipulation\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "\n",
    "# working with data\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# country manipulation\n",
    "import country_converter\n",
    "import pycountry\n",
    "import logging\n",
    "\n",
    "# widgets\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pycountry\n",
    "import plotly.express as px\n",
    "import geopandas\n",
    "import mplcursors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding appropiate datasets.\n",
    "\n",
    "We decided that each person should focus on different categories. Each dataset should be sorted by the combination of country and year. To be consistent with country names we decided to use ISO 3166 alpha 3 country codes.  They categories were divided the following way:\n",
    "\n",
    "\n",
    "* Josef: energy consumption and production data\n",
    "* Felix: ecological data (CO$_2$-emission, pollution, ...)\n",
    "* Frank: economical data (GDP, income, growth, ...)\n",
    "* Johannes: (operating reactors, government, , accidents, climate agreements ...)\n",
    "\n",
    "**Used datasets**\n",
    "\n",
    "All used datasets are in the folder `./data`.\n",
    "\n",
    "* __[U.S. Energy Information Administration](https://www.eia.gov/international/data/world)__\\\n",
    "`USEIA/`\n",
    "* __[Data on CO2 and Greenhouse Gas Emissions by Our World in Data](https://github.com/owid/co2-data)__\\\n",
    "`owid-co2-data.csv`\n",
    "* __[GDP (current USD)](https://data.worldbank.org/indicator/NY.GDP.MKTP.CD)__\\\n",
    "`API_NY.GDP.MKTP.CD_DS2_en_csv_v2_1740389/`\n",
    "* __[GDP growth (annual \\%)](https://data.worldbank.org/indicator/NY.GDP.MKTP.KD.ZG)__\\\n",
    "`API_NY.GDP.MKTP.CD_DS2_en_csv_v2_1740389/`\n",
    "* __[GDP per capita (current USD)](https://data.worldbank.org/indicator/NY.GDP.PCAP.CD)__\\\n",
    "`API_NY.GDP.PCAP.CD_DS2_en_csv_v2_1740213`\n",
    "* __[GDP per capita growth (annual \\%)](https://data.worldbank.org/indicator/NY.GDP.PCAP.KD.ZG)__\\\n",
    "`API_NY.GDP.PCAP.KD.ZG_DS2_en_csv_v2_1740284/`\n",
    "* __[Adjusted net national income per capita (current USD)](https://data.worldbank.org/indicator/NY.ADJ.NNTY.PC.CD)__\\\n",
    "`API_NY.ADJ.NNTY.PC.CD_DS2_en_csv_v2_1745486`\n",
    "* __[Adjusted net national income per capita (annual \\% growth)](https://data.worldbank.org/indicator/NY.ADJ.NNTY.PC.KD.ZG)__ \\\n",
    "`API_NY.ADJ.NNTY.PC.KD.ZG_DS2_en_csv_v2_1745488/`\n",
    "* __[Power Reactor Information System](https://pris.iaea.org/PRIS/CountryStatistics/CountryStatisticsLandingPage.aspx)__\\\n",
    "`reactor_numbers_PRIS_IAEA.csv`\n",
    "* __[Nuclear Wareheads per country](https://data.world/datagraver/nuclear-warheads-per-country)__\\\n",
    "`nuclear_warheads_1945_2016.csv`\n",
    "* __[Gross domestic expenditure on R&D (GERD), GERD as a percentage of GDP](http://data.uis.unesco.org/Index.aspx?DataSetCode=SCN_DS#)__\\\n",
    "`SCN_DS_16122020083400698.csv`\n",
    "* __[Nuclear Power Accidents (Deaths and Costs)](https://data.world/rebeccaclay/nuclear-power-accidents)__\\\n",
    "`C_id_35_NuclearPowerAccidents2016.csv`\n",
    "* __[The Global State of Democracy Indices](https://www.idea.int/gsod-indices/dataset-resources)__\\\n",
    "`gsodi_pv_4.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset loading by Josef**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize CountryConverter as cc and disable warnings\n",
    "country_converter.logging.getLogger().setLevel(logging.CRITICAL)\n",
    "cc = country_converter.CountryConverter()\n",
    "\n",
    "def load_useia_data():\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    ### CONSUMPTION\n",
    "    target = './data/USEIA/USEIA_CONSUMPTION_1980-2018.csv'\n",
    "\n",
    "    consumption = pd.read_csv(target, sep=\",\", decimal=\".\", header=0, skiprows=1, na_values='--')\n",
    "\n",
    "    # rename columns\n",
    "    consumption = consumption.rename(columns={'Unnamed: 1': 'text'})\n",
    "    consumption.insert(loc=0, column='country', value=0)\n",
    "    consumption.insert(loc=0, column='check', value='X')\n",
    "\n",
    "    consumption['country'] = consumption['API'].str[-10:-7]\n",
    "    #consumption = map_historic_countries(consumption)\n",
    "    consumption['check'] = cc.convert(names=consumption['country'].to_list(), to='ISO3')\n",
    "\n",
    "    consumption = consumption.sort_values(by=['country'])\n",
    "\n",
    "    # data cleaning\n",
    "\n",
    "    # remove rows where country code check failed\n",
    "    raw = consumption[consumption['check'] != 'not found']\n",
    "\n",
    "    raw = raw.reset_index(drop=True)\n",
    "\n",
    "    consumption = pd.DataFrame(columns=['year', 'country', 'cons_btu', 'coal_cons_btu', 'gas_cons_btu', \\\n",
    "                                        'oil_cons_btu', 'nuclear_cons_btu', 'renewables_cons_btu'])\n",
    "\n",
    "    countries = pd.DataFrame(raw['country'])\n",
    "    countries.sort_values(by=['country'])\n",
    "    countries.drop_duplicates(inplace=True)\n",
    "    countries = countries.reset_index(drop=True)\n",
    "\n",
    "    counter = 0\n",
    "    for idx1, c in countries.iterrows():\n",
    "\n",
    "        temp = raw[raw['country'] == c.iloc[0]]\n",
    "\n",
    "        j = 4\n",
    "        for i in range(1980, 2019):\n",
    "\n",
    "            v_cons = 0\n",
    "            v_coal = 0\n",
    "            v_gas = 0\n",
    "            v_oil = 0\n",
    "            v_nuclear = 0\n",
    "            v_renewables = 0\n",
    "\n",
    "            new_row = {'year': i, 'country': c.iloc[0]}\n",
    "            for idx2, row in temp.iterrows():\n",
    "\n",
    "                text = row.iloc[3]\n",
    "\n",
    "                if text.find(\"Consumption\") != -1:\n",
    "                    v_cons = row.iloc[j]\n",
    "                elif text.find(\"Coal\") != -1:\n",
    "                    v_coal = row.iloc[j]\n",
    "                elif text.find(\"Natural gas\") != -1:\n",
    "                    v_gas = row.iloc[j]\n",
    "                elif text.find(\"Petroleum\") != -1:\n",
    "                    v_oil = row.iloc[j]\n",
    "                elif text.find(\"Nuclear (\") != -1:\n",
    "                    v_nuclear = row.iloc[j]\n",
    "                elif text.find(\"Renewables and other\") != -1:\n",
    "                    v_renewables = row.iloc[j]\n",
    "\n",
    "            new_row['cons_btu'] = v_cons\n",
    "            new_row['coal_cons_btu'] = v_coal\n",
    "            new_row['gas_cons_btu'] = v_gas\n",
    "            new_row['oil_cons_btu'] = v_oil\n",
    "            new_row['nuclear_cons_btu'] = v_nuclear\n",
    "            new_row['renewables_cons_btu'] = v_renewables\n",
    "\n",
    "            consumption.loc[counter] = new_row\n",
    "            counter += 1\n",
    "            j += 1\n",
    "\n",
    "    ### PRODUCTION\n",
    "    target = './data/USEIA/USEIA_PRODUCTION_1980-2018.csv'\n",
    "\n",
    "    production = pd.read_csv(target, sep=\",\", decimal=\".\", header=0, skiprows=1, na_values='--')\n",
    "\n",
    "    # rename columns\n",
    "    production = production.rename(columns={'Unnamed: 1': 'text'})\n",
    "    production.insert(loc=0, column='country', value=0)\n",
    "    production.insert(loc=0, column='check', value='X')\n",
    "\n",
    "    production['country'] = production['API'].str[-10:-7]\n",
    "    #production = map_historic_countries(production)\n",
    "    production['check'] = cc.convert(names=production['country'].to_list(), to='ISO3')\n",
    "\n",
    "    production.sort_values('country')\n",
    "\n",
    "    # data cleaning\n",
    "\n",
    "    # remove rows where country code check failed\n",
    "    raw = production[production['check'] != 'not found']\n",
    "\n",
    "    raw = raw.reset_index(drop=True)\n",
    "\n",
    "    production = pd.DataFrame(columns=['year', 'country', 'prod_btu', 'coal_prod_btu', 'gas_prod_btu', \\\n",
    "                                       'oil_prod_btu', 'nuclear_prod_btu', 'renewables_prod_btu'])\n",
    "\n",
    "    countries = pd.DataFrame(raw['country'])\n",
    "    countries.sort_values(by=['country'])\n",
    "    countries.drop_duplicates(inplace=True)\n",
    "    countries = countries.reset_index(drop=True)\n",
    "\n",
    "    counter = 0\n",
    "    for idx3, c in countries.iterrows():\n",
    "\n",
    "        temp = raw[raw['country'] == c.iloc[0]]\n",
    "\n",
    "        j = 4\n",
    "        for i in range(1980, 2019):\n",
    "\n",
    "            v_prod = 0\n",
    "            v_coal = 0\n",
    "            v_gas = 0\n",
    "            v_oil = 0\n",
    "            v_nuclear = 0\n",
    "            v_renewables = 0\n",
    "\n",
    "            new_row = {'year': i, 'country': c.iloc[0]}\n",
    "            for idx4, row in temp.iterrows():\n",
    "\n",
    "                text = row.iloc[3]\n",
    "\n",
    "                if text.find(\"Production\") != -1:\n",
    "                    v_prod = row.iloc[j]\n",
    "                elif text.find(\"Coal\") != -1:\n",
    "                    v_coal = row.iloc[j]\n",
    "                elif text.find(\"Natural gas\") != -1:\n",
    "                    v_gas = row.iloc[j]\n",
    "                elif text.find(\"Petroleum\") != -1:\n",
    "                    v_oil = row.iloc[j]\n",
    "                elif text.find(\"Nuclear (\") != -1:\n",
    "                    v_nuclear = row.iloc[j]\n",
    "                elif text.find(\"Renewables and other\") != -1:\n",
    "                    v_renewables = row.iloc[j]\n",
    "\n",
    "            new_row['prod_btu'] = v_prod\n",
    "            new_row['coal_prod_btu'] = v_coal\n",
    "            new_row['gas_prod_btu'] = v_gas\n",
    "            new_row['oil_prod_btu'] = v_oil\n",
    "            new_row['nuclear_prod_btu'] = v_nuclear\n",
    "            new_row['renewables_prod_btu'] = v_renewables\n",
    "\n",
    "            production.loc[counter] = new_row\n",
    "            counter += 1\n",
    "            j += 1\n",
    "\n",
    "    data = pd.merge(consumption, production, how=\"outer\", on=['year', 'country'])\n",
    "\n",
    "    data['year'] = data['year'].astype('int64')\n",
    "    data['nuclear_prod_btu'] = data['nuclear_prod_btu'].astype('float64')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset loading by Felix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_emission_data():\n",
    "    \"\"\" \n",
    "    Load all emission data files and combine them into a single Pandas DataFrame.\n",
    "    Common data structure: 0-year, 1-country code, 2+-features.\n",
    "    Check for correct typing.\n",
    "\n",
    "    return:\n",
    "    emission_data: data frame containing different emission data per country per year.\n",
    "    \"\"\"\n",
    "\n",
    "    path = './data/owid-co2-data.csv'\n",
    "    df_emission_data = pd.read_csv(path, sep=',')\n",
    "\n",
    "    cols = ['year', 'iso_code']\n",
    "    # Rearrange columns, so that year and country-code (iso-code) are the first two columns.\n",
    "    new_cols = cols + df_emission_data.columns.drop(cols).tolist()\n",
    "    # Drop country column.\n",
    "    df_emission_data = df_emission_data[new_cols].drop(['country'], axis=1)\n",
    "    # Rename iso_code to country and convert to string.\n",
    "    df_emission_data[['iso_code']] = df_emission_data[['iso_code']].astype('string')\n",
    "    df_emission_data = df_emission_data.rename(columns={'iso_code': 'country'})\n",
    "    return df_emission_data\n",
    "\n",
    "\n",
    "def resize_emission(df):\n",
    "    \"\"\" Index dataframe and eliminate non-country specific data.\n",
    "\n",
    "    Attention: When handling NaN values look at the values of a specific column, if there exists a NaN value\n",
    "    above/below a 0 entry, it is highly possible that NaN are truly missing values.\n",
    "\n",
    "    Time-range: 1980-2018\n",
    "\n",
    "    return:\n",
    "    trimmed down and somewhat ordered emission_data.\"\"\"\n",
    "    data_emission_i = df.copy()\n",
    "    # Only keep countries (check len(country_code) == 3) - raw data contains continental data, etc. with a blank\n",
    "    # country code (i.e. length 0).\n",
    "    data_emission_i = data_emission_i[data_emission_i['country'].str.len() == 3]\n",
    "    # Set index on country_code and year (group by country_code).\n",
    "    # data_emission_i = data_emission_i.set_index(['country_code', 'year'])\n",
    "    # Keep most interesting columns:\n",
    "    data_emission_i = data_emission_i.drop(data_emission_i.iloc[:, -5:-2], axis=1)\n",
    "    data_emission_i = data_emission_i.drop(data_emission_i.iloc[:, 16:26], axis=1)  # delete cement,... produc. emission\n",
    "    data_emission_i = data_emission_i.drop(['gdp', 'trade_co2', 'trade_co2_share'], axis=1)\n",
    "    return data_emission_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset loading by Frank**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_economical_data():\n",
    "    \"\"\"Load economical data into dataframe and return it.\n",
    "\n",
    "    Common data structure:\n",
    "    0: year\n",
    "    1: country code\n",
    "    3..: features\"\"\"\n",
    "\n",
    "    def get_df(filepath):\n",
    "        df = pd.read_csv(filepath, sep=',', skip_blank_lines=True, header=2)\n",
    "        df.drop(columns_drop, axis=1, inplace=True)\n",
    "        df.rename(columns={'Country Code': 'country'}, inplace=True)\n",
    "        return df\n",
    "\n",
    "    columns_drop = ['Country Name', 'Indicator Name',  'Indicator Code', 'Unnamed: 65']  # columns to drop\n",
    "    dfs = []  # List of all dataframes.\n",
    "\n",
    "    # load dataframe of GDP\n",
    "    df_GDP = get_df('./data/API_NY.GDP.MKTP.CD_DS2_en_csv_v2_1740389/API_NY.GDP.MKTP.CD_DS2_en_csv_v2_1740389.csv')\n",
    "    # melt and order to get in right format\n",
    "    df_GDP = df_GDP.melt(id_vars=['country'], var_name='year', value_name='GDP')\n",
    "    df_GDP['year'] = df_GDP['year'].astype('int64')\n",
    "    dfs.append(df_GDP)\n",
    "\n",
    "    # load dataframe of GDP growth\n",
    "    df_GDP_growth = get_df('./data/API_NY.GDP.MKTP.KD.ZG_DS2_en_csv_v2_1836177/'\n",
    "                           'API_NY.GDP.MKTP.KD.ZG_DS2_en_csv_v2_1836177.csv')\n",
    "    # melt and order to get in right format\n",
    "    df_GDP_growth = df_GDP_growth.melt(id_vars=['country'], var_name='year', value_name='GDP growth')\n",
    "    df_GDP_growth['year'] = df_GDP_growth['year'].astype('int64')\n",
    "    dfs.append(df_GDP_growth)\n",
    "\n",
    "    # load dataframe of GDP per capita\n",
    "    df_GDP_per_capita = get_df('./data/API_NY.GDP.PCAP.CD_DS2_en_csv_v2_1740213/'\n",
    "                               'API_NY.GDP.PCAP.CD_DS2_en_csv_v2_1740213.csv')\n",
    "    # melt and order to get in right format\n",
    "    df_GDP_per_capita = df_GDP_per_capita.melt(id_vars=['country'], var_name='year', value_name='GDP per capita')\n",
    "    df_GDP_per_capita['year'] = df_GDP_per_capita['year'].astype('int64')\n",
    "    dfs.append(df_GDP_per_capita)\n",
    "\n",
    "    # load dataframe of GDP per capita growth\n",
    "    df_GDP_per_capita_growth = get_df('./data/API_NY.GDP.PCAP.KD.ZG_DS2_en_csv_v2_1740284/'\n",
    "                                      'API_NY.GDP.PCAP.KD.ZG_DS2_en_csv_v2_1740284.csv')\n",
    "    # melt and order to get in right format\n",
    "    df_GDP_per_capita_growth = df_GDP_per_capita_growth.melt(id_vars=['country'], var_name='year',\n",
    "                                                             value_name='GDP per capita growth')\n",
    "    df_GDP_per_capita_growth['year'] = df_GDP_per_capita_growth['year'].astype('int64')\n",
    "    dfs.append(df_GDP_per_capita_growth)\n",
    "\n",
    "    # load dataframe of income per capita\n",
    "    df_income_per_capita = get_df('./data/API_NY.ADJ.NNTY.PC.CD_DS2_en_csv_v2_1745486/'\n",
    "                                  'API_NY.ADJ.NNTY.PC.CD_DS2_en_csv_v2_1745486.csv')\n",
    "    # melt and order to get in right format\n",
    "    df_income_per_capita = df_income_per_capita.melt(id_vars=['country'], var_name='year',\n",
    "                                                     value_name='income per capita')\n",
    "    df_income_per_capita['year'] = df_income_per_capita['year'].astype('int64')\n",
    "    dfs.append(df_income_per_capita)\n",
    "\n",
    "    # load dataframe of income per capita growth\n",
    "    df_income_per_capita_growth = get_df('./data/API_NY.ADJ.NNTY.PC.KD.ZG_DS2_en_csv_v2_1745488/'\n",
    "                                         'API_NY.ADJ.NNTY.PC.KD.ZG_DS2_en_csv_v2_1745488.csv')\n",
    "    # melt and order to get in right format\n",
    "    df_income_per_capita_growth = df_income_per_capita_growth.melt(id_vars=['country'], var_name='year',\n",
    "                                                                   value_name='income per capita growth')\n",
    "    df_income_per_capita_growth['year'] = df_income_per_capita_growth['year'].astype('int64')\n",
    "    dfs.append(df_income_per_capita_growth)\n",
    "\n",
    "    # merge and sort all dataframes\n",
    "    result = dfs[0]\n",
    "    for df in dfs[1:]:\n",
    "        result = result.merge(df, how='outer', on=['country', 'year'])\n",
    "    result.sort_values(['country', 'year'], inplace=True)\n",
    "    result.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Since there are some aggregated values (e. g. WLD for world) remove all rows which don't have a valid\n",
    "    # ISO 3166 Alpha-3 code.\n",
    "    alpha_3_list = [country.alpha_3 for country in list(pycountry.countries)]  # all valid codes\n",
    "    valid_entry = result['country'].isin(alpha_3_list)  # boolean series if each row is valid or not\n",
    "    result = result.loc[valid_entry]\n",
    "    # invalid = set(result.loc[~valid_entry]['country'].tolist())\n",
    "    # print('invalid code\\n', invalid)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset loading by Johannes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize CountryConverter as cc and disable warnings\n",
    "country_converter.logging.getLogger().setLevel(logging.CRITICAL)\n",
    "cc = country_converter.CountryConverter()\n",
    "# dictionary for country replacements (that cannot be read by country_converter)\n",
    "# using current ones for outdated names, e.g. 'USSR' --> 'Russia'\n",
    "_dict_country_repl = {'UK':'United Kingdom', 'USSR':'Russia', 'Soviet Union':'Russia', 'East Germany':'Germany',\n",
    "                      'Illinois':'US', 'Tawian':'Taiwan', 'Yugoslavia':'Serbia', 'Scotland':'United Kingdom'}\n",
    "\n",
    "###################################################################################################\n",
    "def load_political_data():\n",
    "    # read data from diffenernt datasets in the category 'political'\n",
    "        \n",
    "    # nuclear wrheads\n",
    "    # read file and exclude last (empty) line\n",
    "    warheads = pd.read_csv('./data/nuclear_warheads_1945_2016.csv', \n",
    "                           sep=';',thousands='.', decimal=',').iloc[:-1]\n",
    "    warheads['Year'] = warheads['Year'].astype('int')\n",
    "    warheads = warheads.set_index('Year')\n",
    "    # transform datafame from 2D to MultiIndex\n",
    "    warheads = warheads.stack()\n",
    "    warheads = warheads.reset_index()\n",
    "    # set column names and convert country names to ISO3\n",
    "    warheads.columns = ['year', 'country', 'nuclear_warheads']\n",
    "    warheads['country'] = cc.convert(warheads['country'].to_list(), to='ISO3')\n",
    "    warheads = warheads.set_index(['year', 'country'])\n",
    "    \n",
    "    \n",
    "    # research expenditure\n",
    "    research = pd.read_csv('./data/SCN_DS_16122020083400698.csv')\n",
    "    # choose only lines with relatilve expenditure (for all reaseach categories)\n",
    "    research = research.loc[research['Indicator']==\"GERD as a percentage of GDP\"]\n",
    "    # chose relevant columns and rename them\n",
    "    research = research[['Time','Country', 'Value']]\n",
    "    research.columns = ['year', 'country', 'research_%GDP']\n",
    "    # convert to ISO3 and exclude regions (cannot be converted to countrycode)\n",
    "    research['country'] = research['country'].replace({'Oceania (Australia/New Zealand)':'not found'})\n",
    "    research['country'] =  cc.convert(research['country'].to_list(), to='ISO3', not_found='not found')\n",
    "    research = research[research['country'] != 'not found']\n",
    "    research = research.set_index(['year', 'country'])\n",
    "\n",
    "    \n",
    "    # accidents of nuclear power plants\n",
    "    accidents = pd.read_csv('./data/C_id_35_NuclearPowerAccidents2016.csv')\n",
    "    accidents = accidents[['Date', 'Location', 'Cost (millions 2013US$)', 'Fatalities']]\n",
    "    accidents.columns = ['year', 'country', 'accident_cost_MioUSD2013', 'accident_deaths']\n",
    "    # use only year from Date column\n",
    "    accidents['year'] = accidents['year'].str.slice(start=-4).astype('int')\n",
    "    # use last part of Location (usually the country)\n",
    "    accidents['country'] = accidents['country'].str.split(',').str[-1].str.lstrip(' ')\n",
    "    # do some corrections (e.g. old country names or missing ones)\n",
    "    accidents['country'] = accidents['country'].replace(_dict_country_repl)\n",
    "    # conversion to ISO3\n",
    "    accidents['country'] = cc.convert(accidents['country'].to_list(), to='ISO3')\n",
    "    accidents = accidents.set_index(['year', 'country'])\n",
    "    # sum values, if there was more than one accident per year and country\n",
    "    accidents = accidents.sum(level=['year','country'])\n",
    "    \n",
    "    # democarcy indicators\n",
    "    democracy = pd.read_csv('./data/gsodi_pv_4.csv', low_memory=False)\n",
    "    # choose five main categories\n",
    "    democracy = democracy[['ID_year','ID_country_name','C_A1','C_A2','C_A3','C_A4','C_SD51']]\n",
    "    democracy.columns = ['year', 'country', 'representative_government', 'fundamental_rights', \n",
    "                         'checks_on_gouvernment', 'impartial_administration', 'civil_society_participation']\n",
    "    # avoid that 'Southern Africa' is converted to 'ZAF' and count 'East Germany' as 'Germany' \n",
    "    democracy['country'] = democracy['country'].replace(\n",
    "            {'Southern Africa':' ','German Democratic Republic':'Germany'})\n",
    "    democracy['country'] = cc.convert(democracy['country'].to_list(), to='ISO3')\n",
    "    # exclude regions (and east germany)\n",
    "    democracy = democracy[democracy['country'] != 'not found']\n",
    "    democracy = democracy.set_index(['year', 'country'])\n",
    "    # use mean value for duplicate values (EAST and WEST GERMANY)\n",
    "    democracy = democracy.mean(level=['year','country'])\n",
    "\n",
    "    # get number of reactors from seperate function\n",
    "    reactors = load_reactor_numbers()\n",
    "    \n",
    "    # merging and fill some of the missing values\n",
    "    merge = pd.concat(\n",
    "            [reactors,warheads,accidents,research,democracy],\n",
    "            axis=1, join='outer')\n",
    "\n",
    "\n",
    "    merge.iloc[:,3] = merge.iloc[:,3].unstack().interpolate().stack()\n",
    "    merge.iloc[:,:3] = merge.iloc[:,:3].fillna(value=0)\n",
    "    \n",
    "    merge = merge.sort_index(level=['country'])\n",
    "    \n",
    "    return merge\n",
    "\n",
    "###################################################################################################\n",
    "def load_reactor_numbers():\n",
    "    # loading number of operational nuclear power plants from IAEA-PRIS database (public version)\n",
    "    \n",
    "    # if data was already loaded from webpages, read directly from saved csv file\n",
    "    if os.path.isfile('./data/reactor_numbers_PRIS_IAEA.csv'):\n",
    "        reactors = pd.read_csv('./data/reactor_numbers_PRIS_IAEA.csv', index_col=[0,1])\n",
    "        return reactors\n",
    "    \n",
    "    # create containers for reactor data per country\n",
    "    startup_dict=dict()\n",
    "    shutdown_dict=dict()\n",
    "\n",
    "    # fetch table for reactors from public webpage\n",
    "    url = 'https://pris.iaea.org/PRIS/CountryStatistics/ReactorDetails.aspx?current='\n",
    "    for num in range(1000): # manual maximal id of reactor\n",
    "        page = requests.get(url+str(num))\n",
    "        if page.status_code < 400: # exclude non-existing IDs\n",
    "            # find country (ISO2) in html and load tables from page\n",
    "            country = re.findall('[\\d\\D]*color=\"DarkGray\"', str(page.content))[0][-26:-24]\n",
    "            country = cc.convert(country, src='ISO2', to='ISO3')\n",
    "            # create dict entries for new countries\n",
    "            if country not in startup_dict.keys():\n",
    "                startup_dict[country] = np.empty(shape=0, dtype='int')\n",
    "                shutdown_dict[country] = np.empty(shape=0, dtype='int')\n",
    "            page_df = pd.read_html(page.content)\n",
    "            if len(page_df) < 3: # exclude reactor if never started\n",
    "                continue\n",
    "            # get year of startup\n",
    "            if page_df[0].iloc[6,1]=='Commercial Operation Date':\n",
    "                # if 'Commercial Operation Date' is not given (NaN), use 'First Grid Connection'\n",
    "                if type(page_df[0].iloc[7,1]) != 'str':\n",
    "                        startup_dict[country] = np.append(startup_dict[country], int(page_df[0].iloc[7,0][-4:]))\n",
    "                else:\n",
    "                    startup_dict[country] = np.append(startup_dict[country], int(page_df[0].iloc[7,1][-4:]))\n",
    "            # get year of reactor shutdown (if given)\n",
    "            if page_df[0].iloc[8,0]=='Permanent Shutdown Date':\n",
    "                shutdown_dict[country] = np.append(shutdown_dict[country], int(page_df[0].iloc[9,0][-4:]))\n",
    "\n",
    "    # calculate operating reactors from startup and shutdown dates\n",
    "    # of each reactor (from dicts) for each country per year\n",
    "    reactors = pd.DataFrame()\n",
    "    for ISO in startup_dict.keys():\n",
    "        if len(startup_dict[ISO])==0:\n",
    "            continue\n",
    "        reactors_country = pd.DataFrame()\n",
    "        reactors_country['year'] = np.arange(startup_dict[ISO].min(),2021)\n",
    "        reactors_country['country'] = np.full(shape=reactors_country.shape[0], fill_value=ISO)\n",
    "        reactors_country['built_reactors'] = np.fromiter(\n",
    "                (startup_dict[ISO][startup_dict[ISO] <= year].size for year in reactors_country['year'] )\n",
    "                ,dtype='int')\n",
    "        reactors_country['shutdown_reactors'] = np.fromiter(\n",
    "                (shutdown_dict[ISO][shutdown_dict[ISO] <= year].size for year in reactors_country['year'] )\n",
    "                ,dtype='int')\n",
    "        reactors_country['operating_reactors'] = reactors_country['built_reactors'] - reactors_country['shutdown_reactors']\n",
    "        reactors = pd.concat([reactors, reactors_country],axis=0)\n",
    "    reactors = reactors.set_index(['year', 'country'])\n",
    "    # save DataFrame to csv-file, to fetch data not everytime\n",
    "    reactors.to_csv('./data/reactor_numbers_PRIS_IAEA.csv')\n",
    "    return reactors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging datasets\n",
    "\n",
    "This was worked on by Frank. The function <span style=\"color:blue\">clean_data_after_merge()</span> was written by Johannes. Since running the cell below takes a lot of time, the merged and cleaned dataframe was written to `./data/data_merged/data.csv`. For exploring the data, loading the csv was much faster than running the code in the next cell each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_after_merge(df):\n",
    "    \"\"\"Fill some missing data in merged dataframe.\"\"\"\n",
    "\n",
    "    for column in ['built_reactors', 'shutdown_reactors', 'operating_reactors', 'nuclear_warheads']:\n",
    "        df[column].fillna(value=0, inplace=True)\n",
    "    for column in ['accident_cost_MioUSD2013', 'accident_deaths']:\n",
    "        df[column].fillna(value=0, inplace=True)\n",
    "\n",
    "        \n",
    "df_energy = load_useia_data()\n",
    "df_emission = resize_emission(load_emission_data())\n",
    "df_economy = load_economical_data()\n",
    "df_politics = load_political_data()\n",
    "df_politics.reset_index(drop=False, inplace=True)\n",
    "\n",
    "# merge all dataframes:\n",
    "dataframe = df_energy\n",
    "for df in [df_emission, df_economy, df_politics]:\n",
    "    dataframe = dataframe.merge(df, how='left', on=['year', 'country'])\n",
    "\n",
    "# clean up some values\n",
    "clean_data_after_merge(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation and Comments about used datasets:\n",
    "\n",
    "This part was written by all members.\n",
    "\n",
    "page 5 of exercise3.pdf\n",
    "\n",
    "conversion quad btu to EJ\n",
    "how to format this part? Everyone their own thoughts? All together?\n",
    "\n",
    "For some information ('built_reactors', 'shutdown_reactors', 'operating_reactors', 'nuclear_recators', 'accident_cost_MioUSD2013', 'accident_deaths') we decided to fill the missing values with the number 0. It was deemed an appropiate solution since there are not a lot of accidents with nuclear power plants (obvious ones like Chernobyl and Fukushima were in the data). \n",
    "\n",
    "suggestion: country conversion (USSR), Felix GHG vs CO$_2$ only, Johannes fillna(0) for missing values\n",
    "\n",
    "Individual observations:\n",
    "\n",
    "* Josef\n",
    "* Frank \\\n",
    "    Since it was decided beforehand what each person had to search, it was much easier for me to narrow down what to look for. I found data in .csv and .xslx formats. Of these I thought that .csv formats are easier to work in python with. Some web ruslts only offer datasets behind a paywall, which could not be used for this exercise.\n",
    "* Felix\n",
    "* Johannes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Visualization of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for the cell below was written by Josef. The code for the dropdown widget was added by Frank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_data_for_plot():\n",
    "\n",
    "    desc_file = './data/data_merged/description.csv'\n",
    "    data_file = './data/data_merged/data.csv'\n",
    "\n",
    "    desc = pd.read_csv(desc_file, sep=\",\", header=None)\n",
    "    desc.set_index(0, inplace=True)\n",
    "    data = pd.read_csv(data_file, sep=\",\", decimal=\".\")\n",
    "\n",
    "\n",
    "\n",
    "    return data, desc\n",
    "\n",
    "\n",
    "def show_map(df, desc, feature, scope):\n",
    "    # print(df)\n",
    "    # print(desc)\n",
    "\n",
    "    minimum = df[feature].min()\n",
    "    maximum = df[feature].max()\n",
    "\n",
    "    fig = px.choropleth(data_frame=df,\n",
    "                        locations=\"country\",\n",
    "                        color=feature,  # value in feature column determines color\n",
    "                        hover_name=\"country\",\n",
    "                        scope=scope,\n",
    "                        color_continuous_scale='Reds',  # color scale\n",
    "                        range_color=(minimum, maximum),\n",
    "                        animation_frame=\"year\",\n",
    "                        title='Development of feature ' + feature + ': ' + desc)\n",
    "    # do not show antarctica in world map\n",
    "    if scope == 'world':\n",
    "        fig.layout.geo.lataxis.range = [-55, 90]\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def wrapper(feature):\n",
    "    description = desc.loc[feature][1]\n",
    "    # change scope if necessary (usa, europe, asia, africa, north america, ...)\n",
    "    show_map(df, description, feature, 'world')\n",
    "\n",
    "\n",
    "df, desc = load_data_for_plot()\n",
    "\n",
    "options = df.columns.drop(['year', 'country'])\n",
    "widgets.interact(wrapper, feature=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for the cell below was written by Johannes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_for_plot(f):\n",
    "\n",
    "    desc_file = './data/data_merged/description.csv'\n",
    "    data_file = './data/data_merged/data.csv'\n",
    "\n",
    "    d = pd.read_csv(desc_file, sep=\",\", header=None)\n",
    "\n",
    "    row = d.loc[d[0] == f]\n",
    "    feature_desc = row.iat[0, 1].strip()\n",
    "    # feature_idx = row.index[0]\n",
    "\n",
    "    data = pd.read_csv(data_file, sep=\",\", decimal=\".\")\n",
    "\n",
    "    data = data[['year', 'country', f]]\n",
    "\n",
    "    return data, feature_desc\n",
    "\n",
    "\n",
    "def show_map(df, desc, feature, scope):\n",
    "    # print(df)\n",
    "    # print(desc)\n",
    "\n",
    "    minimum = df[feature].min()\n",
    "    maximum = df[feature].max()\n",
    "\n",
    "    fig = px.choropleth(data_frame=df,\n",
    "                        locations=\"country\",\n",
    "                        color=feature,  # value in feature column determines color\n",
    "                        hover_name=\"country\",\n",
    "                        scope=scope,\n",
    "                        color_continuous_scale='Reds',  # color scale\n",
    "                        range_color=(minimum, maximum),\n",
    "                        animation_frame=\"year\",\n",
    "                        title='Development of feature ' + feature + ': ' + desc)\n",
    "    # do not show antarctica in world map\n",
    "    if scope == 'world':\n",
    "        fig.layout.geo.lataxis.range = [-55, 90]\n",
    "    fig.show()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "feature = \"operating_reactors\"\n",
    "df, desc = load_data_for_plot(feature)\n",
    "show_map(df, desc, feature, 'world')  # usa, europe, asia, africa, north america, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize CountryConverter as cc and disable warnings\n",
    "cc = country_converter.CountryConverter()\n",
    "\n",
    "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "# drop antarctica\n",
    "world = world.drop(world.index[159])\n",
    "# in provided dataframe, some ISO codes (France) are wrong, so let's use the converter\n",
    "world['iso_a3'] = cc.convert(world['name'].to_list(), to='ISO3')\n",
    "\n",
    "# get data of nuclear reactors\n",
    "data = pd.read_csv('./data/data_merged/data.csv').set_index(['year', 'country'])\n",
    "data = data[['built_reactors', 'shutdown_reactors', 'operating_reactors']]\n",
    "\n",
    "\n",
    "# merge with geographical data\n",
    "def merge_year(year):\n",
    "    merge = pd.merge(world, data.loc[year].replace(0, np.nan), left_on='iso_a3', right_on='country', how='left')\n",
    "    return merge\n",
    "\n",
    "\n",
    "# create plots for given years\n",
    "years = [1980, 1985, 1990, 1995, 2000, 2005, 2010, 2015, 2018]\n",
    "fig, ax = plt.subplots(math.ceil(len(years)/3), 3, constrained_layout=True,\n",
    "                       sharex=True, sharey=True,\n",
    "                       subplot_kw=dict(aspect='equal'), figsize=(16, 9))\n",
    "# flatten axes for iteration\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "    merge_year(year).plot(\n",
    "        column='operating_reactors',\n",
    "        ax=ax[i],\n",
    "        missing_kwds={\"color\": \"lightgrey\", \"label\": \"No nuclear power plants\"},  # missing values in grey\n",
    "        cmap='Reds',  # scheme of colormap\n",
    "        vmin=0,\n",
    "        vmax=data.query(\"year in @years\")['operating_reactors'].max()  # set maximum of legend (would be different for every subplot)\n",
    "        )\n",
    "    ax[i].set_title(f'{year}')\n",
    "    ax[i].axis('off')\n",
    "patch_col = ax[0].collections[0]\n",
    "fig.colorbar(patch_col, ax=ax, shrink=0.5)\n",
    "fig.suptitle('Operating nuclear reactors per year (Grey color if zero)')\n",
    "# plt.show()\n",
    "\n",
    "# second plot for evolution of total reactors worldwide\n",
    "data_sum = data.sum(axis=0, level='year').sort_index()\n",
    "data_sum.plot()\n",
    "plt.legend(loc='best')\n",
    "plt.title('Total Nuclear Reactors Worldwide')\n",
    "plt.xlim(data_sum.index.min(), data_sum.index.max())\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: How has the use of nuclear energy evolved over time?\n",
    "\n",
    "The code to answer this question was generated by Josef."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_data_q1():\n",
    "    desc_file = './data/data_merged/description.csv'\n",
    "    data_file = './data/data_merged/data.csv'\n",
    "\n",
    "    data = pd.read_csv(data_file, sep=\",\", decimal=\".\")\n",
    "\n",
    "    data = data[['year', 'country',\n",
    "                 'cons_btu', 'coal_cons_btu', 'gas_cons_btu', 'oil_cons_btu', 'nuclear_cons_btu', 'renewables_cons_btu',\n",
    "                 'prod_btu', 'coal_prod_btu', 'gas_prod_btu', 'oil_prod_btu', 'nuclear_prod_btu',\n",
    "                 'renewables_prod_btu', 'accident_deaths', 'operating_reactors']]\n",
    "\n",
    "    # convert quad btu in EJ (except for first two and last two columns)\n",
    "    conversion_factor = 1.055\n",
    "    data.iloc[:,2:-2] = data.iloc[:,2:-2] * conversion_factor\n",
    "    return data\n",
    "\n",
    "\n",
    "def show_plot0(df):\n",
    "    df1 = df[['year', 'oil_prod_btu', 'coal_prod_btu', 'gas_prod_btu', 'nuclear_prod_btu', 'renewables_prod_btu']]\n",
    "\n",
    "    df1 = df1.groupby(['year']).sum()\n",
    "\n",
    "    y = [df1[\"nuclear_prod_btu\"], df1[\"oil_prod_btu\"], df1[\"coal_prod_btu\"], df1[\"gas_prod_btu\"],\n",
    "         df1[\"renewables_prod_btu\"]]\n",
    "\n",
    "    colors = ['yellow', 'dimgray', 'black', 'darkcyan', 'green']\n",
    "    labels = ['nuclear', 'oil', 'coal', 'gas', 'renewables and other']\n",
    "\n",
    "    plt.stackplot(df1.index, y, labels=labels, colors=colors)\n",
    "\n",
    "    plt.title('Overall energy production 1980-2018')\n",
    "    plt.xlabel(xlabel='year')\n",
    "    plt.ylabel(ylabel='production in EJ')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlim(df['year'].min(), df['year'].max())\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def show_plot1(df):\n",
    "    df1 = df[['year', 'oil_prod_btu', 'coal_prod_btu', 'gas_prod_btu', 'nuclear_prod_btu', 'renewables_prod_btu']]\n",
    "\n",
    "    df1 = df1.groupby(['year']).sum()\n",
    "\n",
    "    y = [df1[\"nuclear_prod_btu\"], df1[\"oil_prod_btu\"], df1[\"coal_prod_btu\"], df1[\"gas_prod_btu\"],\n",
    "         df1[\"renewables_prod_btu\"]]\n",
    "\n",
    "    y0 = (y[0] / (y[0] + y[1] + y[2] + y[3] + y[4]) * 100)\n",
    "    y1 = (y[1] / (y[0] + y[1] + y[2] + y[3] + y[4]) * 100)\n",
    "    y2 = (y[2] / (y[0] + y[1] + y[2] + y[3] + y[4]) * 100)\n",
    "    y3 = (y[3] / (y[0] + y[1] + y[2] + y[3] + y[4]) * 100)\n",
    "    y4 = (y[4] / (y[0] + y[1] + y[2] + y[3] + y[4]) * 100)\n",
    "\n",
    "    percent = [y0, y1, y2, y3, y4]\n",
    "\n",
    "    colors = ['yellow', 'dimgray', 'black', 'darkcyan', 'green']\n",
    "    labels = ['nuclear', 'oil', 'coal', 'gas', 'renewables and other']\n",
    "\n",
    "    plt.stackplot(df1.index, percent, labels=labels, colors=colors)\n",
    "\n",
    "    plt.title('Distribution of energy production 1980-2018')\n",
    "    plt.xlabel(xlabel='year')\n",
    "    plt.ylabel(ylabel='production in %')\n",
    "    plt.legend(loc=(0.01, 0.1))\n",
    "    plt.xlim(df['year'].min(), df['year'].max())\n",
    "    plt.ylim((0, 100))\n",
    "    ax2 = plt.twinx()\n",
    "    ax2.set_ylim((0, 100))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def show_plot2(df):\n",
    "    df1 = df[['year', 'oil_prod_btu', 'coal_prod_btu', 'gas_prod_btu', 'renewables_prod_btu', 'nuclear_prod_btu']]\n",
    "    df1 = df1.groupby(['year']).sum()\n",
    "    df1 = df1.rename(columns={'oil_prod_btu': 'oil', 'coal_prod_btu': 'coal', 'gas_prod_btu': 'gas',\n",
    "                              'renewables_prod_btu': 'renewables', 'nuclear_prod_btu': 'nuclear'})\n",
    "    df1 = df1.reset_index()\n",
    "\n",
    "    df2 = df[['year', 'accident_deaths']]\n",
    "    df2 = df2.groupby(['year']).sum()\n",
    "\n",
    "    ax = plt.gca()\n",
    "\n",
    "    df1.plot(kind='line', x='year', y='nuclear', color='yellow', ax=ax, linewidth=3)\n",
    "    df1.plot(kind='line', x='year', y='oil', color='dimgray', ax=ax, linewidth=3)\n",
    "    df1.plot(kind='line', x='year', y='coal', color='black', ax=ax, linewidth=3)\n",
    "    df1.plot(kind='line', x='year', y='gas', color='darkcyan', ax=ax, linewidth=3)\n",
    "    df1.plot(kind='line', x='year', y='renewables', color='green', ax=ax, linewidth=3)\n",
    "\n",
    "    plt.title('energy prod per energy source incl deaths in nuclear power plants')\n",
    "    plt.xlabel(xlabel='year')\n",
    "    plt.ylabel(ylabel='production in EJ')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid()\n",
    "    plt.xlim(df['year'].min(), df['year'].max())\n",
    "\n",
    "    shift = -4\n",
    "    for x, y in zip(df1['year'], df1['nuclear']):\n",
    "        label = df2.loc[x]\n",
    "        if label[0] > 0:\n",
    "            plt.annotate(label[0].astype('int32'), (x, y + shift), fontweight='bold')\n",
    "            shift = shift * -1\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def show_plot3(df):  # top 10 nuclear energy producers 1980 vs 2018\n",
    "\n",
    "    df['year'] = df['year'].astype('int32')\n",
    "\n",
    "    df1 = df.where(df[\"year\"] == 1998)\n",
    "    df2 = df1.groupby(['country']).sum()\n",
    "    df2 = df2.sort_values(by=['nuclear_prod_btu'], ascending=False)\n",
    "    df2 = df2[['nuclear_prod_btu', 'operating_reactors']].head(20)\n",
    "    df2.rename(columns={'operating_reactors': 'op_reactors_1998', 'nuclear_prod_btu': 'nuclear_prod_1998'},\n",
    "               inplace=True)\n",
    "    df2.insert(0, 'rank1998', range(1, 21))\n",
    "\n",
    "    df3 = df.where(df[\"year\"] == 2018)\n",
    "    df4 = df3.groupby(['country']).sum()\n",
    "    df4 = df4.sort_values(by=['nuclear_prod_btu'], ascending=False)\n",
    "    df4 = df4[['nuclear_prod_btu', 'operating_reactors']].head(20)\n",
    "    df4.rename(columns={'operating_reactors': 'op_reactors_2018', 'nuclear_prod_btu': 'nuclear_prod_2018'},\n",
    "               inplace=True)\n",
    "    df4.insert(0, 'rank2018', range(1, 21))\n",
    "\n",
    "    df5 = df2.merge(df4, how='outer', on=['country'])\n",
    "    df5 = df5.fillna(0)\n",
    "    df5.insert(0, 'movement', (df5['rank1998'] - df5['rank2018']).astype('int32'))\n",
    "\n",
    "    df5['movement'] = np.where((df5.rank1998 == 0), 0, df5.movement)\n",
    "    df5['movement'] = np.where((df5.rank2018 == 0), 0, df5.movement)\n",
    "\n",
    "    df6 = df.groupby(['country']).sum()\n",
    "    df6 = df6[['accident_deaths']]\n",
    "\n",
    "    df7 = df5.merge(df6, how='left', on=['country'])\n",
    "\n",
    "    # print(df7)\n",
    "\n",
    "    df8 = df7.drop(columns=['accident_deaths', 'op_reactors_1998', 'op_reactors_2018',\n",
    "                            'movement', 'rank2018', 'rank1998'])\n",
    "\n",
    "    # figsize\n",
    "    fig, ax = plt.subplots(figsize=(16, 9))\n",
    "    \n",
    "    df8.plot(kind=\"bar\", ax=ax)\n",
    "    plt.title('Nuclear production comparison 1998, 2018')\n",
    "    plt.xlabel(xlabel='')\n",
    "    plt.ylabel(ylabel='production in EJ')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.gca().set_xticks([])\n",
    "\n",
    "    df9 = df7[['rank1998', 'rank2018', 'movement', 'op_reactors_1998', 'op_reactors_2018', 'accident_deaths']]\n",
    "    df9.insert(5, 'change2', (df9['op_reactors_2018'] - df9['op_reactors_1998']).astype('int32'))\n",
    "    df9['change2'] = np.where((df9.op_reactors_1998 == 0), 0, df9.change2)\n",
    "    df9['change2'] = np.where((df9.op_reactors_2018 == 0), 0, df9.change2)\n",
    "    df9 = df9.T\n",
    "    rowlabels = ['rank 1998', 'rank 2018', 'delta ranking', 'reactors 1998', 'reactors 2018', 'delta reactors', 'deaths']\n",
    "    the_table = plt.table(cellText=df9.astype('int').values,\n",
    "                          rowLabels=rowlabels,\n",
    "                          colLabels=df9.columns,\n",
    "                          cellLoc='right', rowLoc='center',\n",
    "                          loc='bottom')\n",
    "    the_table.auto_set_font_size(False)\n",
    "    the_table.set_fontsize(14)\n",
    "    the_table.scale(1,2)\n",
    "\n",
    "    plt.subplots_adjust(bottom=0.3)\n",
    "\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def show_plot4(df):\n",
    "    df0 = df[['year', 'renewables_prod_btu', 'nuclear_prod_btu', 'country', 'accident_deaths']]\n",
    "    df0.index = df0.year\n",
    "\n",
    "    df1 = df0[df0['country'] == 'JPN']\n",
    "    df2 = df0[df0['country'] == 'UKR']\n",
    "\n",
    "    df1 = df1.rename(columns={'renewables_prod_btu': 'renewables JPN', 'nuclear_prod_btu': 'nuclear JPN'})\n",
    "    df2 = df2.rename(columns={'renewables_prod_btu': 'renewables UKR', 'nuclear_prod_btu': 'nuclear UKR'})\n",
    "\n",
    "    ax = plt.gca()\n",
    "\n",
    "    df1.plot(kind='line', x='year', y='renewables JPN', color='green', ax=ax, linewidth=3)\n",
    "    df1.plot(kind='line', x='year', y='nuclear JPN', color='yellow', ax=ax, linewidth=3)\n",
    "    df2.plot(kind='line', x='year', y='renewables UKR', color='darkgreen', ax=ax, linewidth=3)\n",
    "    df2.plot(kind='line', x='year', y='nuclear UKR', color='darkolivegreen', ax=ax, linewidth=3)\n",
    "\n",
    "    plt.title('Comparison of energy prod in JPN and UKR')\n",
    "    plt.xlabel(xlabel='years')\n",
    "    plt.ylabel(ylabel='production in EJ')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid()\n",
    "\n",
    "    shift = 0\n",
    "    for x, y in zip(df1.year, df1['nuclear JPN']):\n",
    "        label = df1.loc[x].accident_deaths\n",
    "        # print(label)\n",
    "        if label > 0:\n",
    "            plt.annotate(label.astype('int32'), (x, y + shift), fontweight='bold')\n",
    "            shift = shift * -1\n",
    "\n",
    "    shift = 0\n",
    "    for x, y in zip(df2.year, df2['nuclear UKR']):\n",
    "        label = df2.loc[x].accident_deaths\n",
    "        # print(label)\n",
    "        if label > 0:\n",
    "            plt.annotate(label.astype('int32'), (x, y + shift), fontweight='bold')\n",
    "            shift = shift * -1\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "df = load_data_q1()\n",
    "show_plot0(df)\n",
    "show_plot1(df)\n",
    "show_plot2(df)\n",
    "show_plot3(df)\n",
    "show_plot4(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "* Overall energy production\\\n",
    "Shows overall development of energy production over time in quadrillion\n",
    "btu. In the selected timeframe (past 38 years) the overall energy\n",
    "requirements almost doubled. Annual production of all types of energy climbed.\n",
    "oil +46 %, coal +239 %, gas +279 %, nuclear +384 %, renewables + 340 %\n",
    "(1980 vs 2018)\n",
    "<br> <span style=\"color:red\">todo_frank nuclear factor=3.83 therefore + 283 %; all other probably too</span>\n",
    "\n",
    "\n",
    "* Distribution of energy production\\\n",
    "The stacked area chart is focusing on the composition (by energy source).\n",
    "In 1980 we see about 90% fossil energy sources, 3% nuclear and 7% renewables.\n",
    "Whereas in 2018 fossil energy sources drop to 84%, nuclear 4.4% and\n",
    "renewables 11.4%\n",
    "\n",
    "\n",
    "* line plot with annotations\\\n",
    "Shows energy production per energy source including reported number of deaths from accidents\n",
    "in nuclear power plants.\n",
    "Annual increase in average (1980-2018)\n",
    "\\+3,7\\% nuclear production and +3,2% renewables / others.\n",
    "However since 2000, nuclear energy production started to stagnate.\n",
    "But production of renewables doubled (from 32.1 to 68.35 quadrillion btu)\n",
    "Remark coal production:\n",
    "The reason of the climb and the shape of the curve is due to the rapid growth in China,\n",
    "which is predominant on the coal market.\n",
    "<br> <span style=\"color:red\">todo_frank btu to EJ</span>\n",
    "\n",
    "\n",
    "* Bar plot with data table attached\\\n",
    "USA and France are leading the ranking in 1998 as well as 2018.\n",
    "China catched up and is now #3\n",
    "The top 7 countries increased production in selected timeframe.\n",
    "Further observations:\n",
    "EU countries decrease production and a reduce number of operating reactors.\n",
    "Japan reduced production and number of reactors significantly, obviously driven by recent accidents. <span style=\"color:red\">todo_frank accident (singular)</span>\n",
    "In the Ukraine the development stagnates. No decline due to Chernobyl disaster in 1986.\n",
    "\n",
    "\n",
    "* Comparison of energy production in JPN and UKR\\\n",
    "Since Japan and Ukraine had the biggest nuclear catastrophes, we decided to selectively have a closer look at these two countries. The Fukushima Daiichi Accident happened in March 2011. An immediate drop of nuclear power production can be observed since Japan decided to shut down almost all reactors.\n",
    "The Chernobyl disaster occured in April 1986. Since Ukraine was part of the USSR that time, we do not have data about energy production. <span style=\"color:red\">todo_frank what did Josef do when changing to alpha-3 codes?</span> The data shows that the country does not have major changes in nuclear and renewable energy production since 1992.\n",
    "<br> <span style=\"color:red\">todo_frank color palette in show_plot4</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: How well does the use of nuclear energy correlate with changes in carbon emissions?\n",
    "\n",
    "The code to answer this question was generated by Felix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Are there characteristics of a country that correlate with increases or decreases in the use of nuclear energy?\n",
    "\n",
    "The code to answer this question was generated by Johannes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading, Selection of Data**\n",
    "<br> <span style=\"color:red\">todo_frank did not use data cleaning as talked in meeting 2021-01-17</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = country_converter.CountryConverter()\n",
    "data = pd.read_csv('./data/data_merged/data.csv')\n",
    "#data = clean_data_after_merge(data).set_index(['year','country']).sort_index()\n",
    "data = data.set_index(['year','country']).sort_index()\n",
    "data = data[\n",
    "    [# economy\n",
    "     'population','GDP','GDP growth', 'GDP per capita', 'GDP per capita growth',\n",
    "     'income per capita', 'income per capita growth', \n",
    "     # political \n",
    "     'research_%GDP','representative_government', 'fundamental_rights',\n",
    "     'checks_on_gouvernment', 'impartial_administration','civil_society_participation',\n",
    "     'nuclear_warheads','accident_cost_MioUSD2013', 'accident_deaths',\n",
    "     # nuclear energy \n",
    "     'built_reactors', 'shutdown_reactors', 'operating_reactors',\n",
    "     'prod_btu', 'nuclear_prod_btu']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many humans live in counties that use nuclear energy? Was there a big change in the last 4 decades? Can we see a tendency of a correlation between the size of a nation (population) and if it uses nuclear energy?**\n",
    "\n",
    "> One can see, that mostly big countries have operating nuclear power plants. Since the startup of the first reactor in China in 1991, more than half of the world's population live in countries that use nuclear energy. However, one can see that only a small fraction of all countries use nuclear power, because there are many small nations without reactors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_population_countries(data):  \n",
    "    data['BOOL'] = (data['operating_reactors']>0)\n",
    "    df = pd.DataFrame()\n",
    "    df['is nuclear'] = data['population'][data['BOOL']].sum(level='year')\n",
    "    df['not nuclear'] = data['population'][~data['BOOL']].sum(level='year')\n",
    "    \n",
    "    %matplotlib inline\n",
    "    fig, ax = plt.subplots(1,2, figsize=[15,5])\n",
    "    \n",
    "    df.plot(kind='area', ax=ax[0])\n",
    "    ax[0].set_ylabel('Cummulative Population')\n",
    "    ax[0].set_xlim(df.index.min(),df.index.max())\n",
    "    ax[0].set_title('Cummulative Population', fontsize=14)\n",
    "    \n",
    "    ycoord = 0.5 * (df.loc[1990,'is nuclear'] + df.loc[1991,'is nuclear'])\n",
    "    ax[0].annotate(text = \"China starts it's first nuclear reactor\",\n",
    "                   xy=(1990.5,ycoord),\n",
    "                   xytext=(1990.5+2,ycoord*0.5),\n",
    "                   ha='left', arrowprops=dict(arrowstyle='->'))\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['is nuclear'] = data['BOOL'].sum(level='year')\n",
    "    df['not nuclear'] = (~data['BOOL']).sum(level='year')\n",
    "    \n",
    "    df.plot(kind='area', ax=ax[1])\n",
    "    ax[1].set_ylabel('Number of Countries')\n",
    "    ax[1].set_xlim(df.index.min(),df.index.max())\n",
    "    ax[1].set_title('Number of Countries', fontsize=14)\n",
    "    return None\n",
    "\n",
    "plot_population_countries(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there correlations between the change of nuclear energy production and the change of other properties of a nation?\n",
    "\n",
    "#### Compare data of two years (e.g. 1998 and 2018) and make scatterplots (for comparison of countries).\n",
    "\n",
    "Compare relative change of following features with the relative change of nuclear energy production between two countries:\n",
    "\n",
    "    population, GDP, GDP per capita, income per capita, research_%GDP, representative_government, fundamental_rights, checks_on_gouvernment, impartial_administration, civil_society_participation, nuclear_warheads\n",
    "    \n",
    "Although there can be seen no absolute tendencies, that are valid for most of the counties, the data of the different countries can be compared very well with the following function for plotting.\n",
    "\n",
    "#### Usage of Plots:\n",
    "\n",
    "`compare_years(data_cleaned,`**`feature(s) to plot, start year, end year`**`);`\n",
    "\n",
    "By default, only the countries with nuclear reactors are shown (`nuclear_countries_only=True`). All countries are plotted, if this value is set to `False`, in case the data for the featue (y-axis) exists.\n",
    "\n",
    "*To show the ISO3 code of the countires, click on a point (works as long as it is in 'interactive' mode). To hide ISO3 again, right-click on the text.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_years(data, features, start, end, nuclear_countries_only=True):\n",
    "    # exclude countries, that do not use nuclear energy (in both year)\n",
    "    if nuclear_countries_only:\n",
    "        nuclear_countries = data.loc[[1998,2018],'operating_reactors'].sum(axis=0, level='country').replace(0,np.nan).dropna().index\n",
    "        data = data.query(\"country in @nuclear_countries\")\n",
    "    if type(features)!=list: features = [features]\n",
    "    df = data[features+['nuclear_prod_btu']]\n",
    "    data_start = df.xs(start, level='year')\n",
    "    data_end   = df.xs(end, level='year')\n",
    "    data_quot  = (data_end.divide(data_start)-1).sort_index() # relative change\n",
    "    \n",
    "    # fill missing values\n",
    "    data_quot['nuclear_prod_btu']  = data_quot['nuclear_prod_btu'].fillna(0)\n",
    "    data_quot  = data_quot.fillna(-np.inf)\n",
    "    \n",
    "    # get continent information (for colorcode of scatterplots)\n",
    "    data_quot['Continent'] = cc.convert(data_quot.index.get_level_values('country').to_list(), src='ISO3', to='continent')\n",
    "    \n",
    "    # scale down countries with large change in nuclear production\n",
    "    max_quot_nuc_prod = data_quot[data_quot['nuclear_prod_btu']>2]['nuclear_prod_btu'].to_dict()\n",
    "    data_quot.loc[max_quot_nuc_prod.keys(),'nuclear_prod_btu'] = 2\n",
    "    \n",
    "    # make interactive plot\n",
    "    %matplotlib notebook\n",
    "    for feature in features:\n",
    "        fig, ax = plt.subplots(figsize=[10,7])\n",
    "        sns.scatterplot(data=data_quot, \n",
    "                x='nuclear_prod_btu', y=feature,\n",
    "                hue='Continent', legend='full', ax = ax,\n",
    "                palette={'Asia':'C0','Europe':'C1','Africa':'C2','America':'C3','Oceania':'C4','Antarctica':'C5'}\n",
    "        )\n",
    "        ax.set_title(feature.upper() + f', relative change from {start} to {end}')\n",
    "        ax.set_xlabel('Nuclear Production, Relative Change')\n",
    "\n",
    "        # Show ISO code of country when clicking\n",
    "        mplcursors.cursor(multiple = True).connect(\n",
    "            \"add\", lambda sel: sel.annotation.set_text(\n",
    "                  data_quot.index[sel.target.index]\n",
    "        ))\n",
    "\n",
    "        # Add arrows for countries with large change in nuclear production (that were scaled down)\n",
    "        for ISO3 in max_quot_nuc_prod.keys():\n",
    "            ax.annotate(text=f'{max_quot_nuc_prod[ISO3]:.1f}',\n",
    "                       xy=(2,data_quot.loc[ISO3,feature]),\n",
    "                       xytext=(2.2,data_quot.loc[ISO3,feature]),\n",
    "                       ha='left', va='center', arrowprops=dict(arrowstyle='<-', color='C0'))\n",
    "\n",
    "        # Move Axes to centre, passing through (0,0)\n",
    "        ax.spines['left'].set_position('zero')\n",
    "        ax.spines['bottom'].set_position('zero')\n",
    "        ax.spines['right'].set_color('none')\n",
    "        ax.spines['top'].set_color('none')\n",
    "\n",
    "        ax.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    return data_quot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure why, but the cell below needs to be run twice.\n",
    "<br> <span style=\"color:red\">todo_frank fix possible?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features = ['population','GDP','GDP per capita','income per capita','research_%GDP','representative_government','fundamental_rights',\n",
    "                'checks_on_gouvernment','impartial_administration','civil_society_participation','nuclear_warheads']\n",
    "\n",
    "test = compare_years(data, features, 1998, 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
